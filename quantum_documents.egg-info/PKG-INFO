Metadata-Version: 2.4
Name: quantum-documents
Version: 0.2.1
Summary: Quantum Documents: Advanced AI-powered document processing and RAG platform
Home-page: https://github.com/your-username/quantum-documents
Author: Your Name or Organization
Author-email: your.email@example.com
License: Apache-2.0
Keywords: LLM,AI,RAG,Document AI
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: gradio>=4.25.0
Requires-Dist: gradio-client>=0.15.0
Requires-Dist: gradio>=4.25.0
Requires-Dist: gradio>=4.25.0
Requires-Dist: gradio-client>=0.15.0
Requires-Dist: gradio==4.44.0
Requires-Dist: gradio_client==1.3.0
Requires-Dist: uvicorn[standard]
Requires-Dist: gunicorn
Requires-Dist: fastapi-utils
Requires-Dist: sse_starlette>=1.8.2
Requires-Dist: huggingface_hub==0.25.2
Requires-Dist: appdirs>=1.4.4
Requires-Dist: fire>=0.5.0
Requires-Dist: docutils>=0.20.1
Requires-Dist: torch==2.2.1; sys_platform != "darwin" and platform_machine != "arm64"
Requires-Dist: torch==2.3.1; sys_platform == "darwin" and platform_machine == "arm64"
Requires-Dist: evaluate>=0.4.0
Requires-Dist: rouge_score>=0.1.2
Requires-Dist: sacrebleu>=2.3.1
Requires-Dist: scikit-learn>=1.2.2
Requires-Dist: numpy<2.0,>=1.23.4
Requires-Dist: pandas>=2.0.2
Requires-Dist: matplotlib>=3.7.1
Requires-Dist: loralib>=0.1.2
Requires-Dist: bitsandbytes>=0.43.1; sys_platform != "darwin" and platform_machine != "arm64"
Requires-Dist: bitsandbytes==0.42.0; sys_platform == "darwin" and platform_machine == "arm64"
Requires-Dist: accelerate>=0.30.1
Requires-Dist: peft>=0.7.0
Requires-Dist: transformers>=4.45.1
Requires-Dist: jinja2>=3.1.0
Requires-Dist: tokenizers>=0.19.0
Requires-Dist: hf_transfer>=0.1.6
Requires-Dist: datasets>=2.18.0
Requires-Dist: sentencepiece>=0.2.0
Requires-Dist: APScheduler>=3.10.1
Requires-Dist: pynvml>=11.5.0
Requires-Dist: psutil>=5.9.5
Requires-Dist: boto3>=1.26.101
Requires-Dist: botocore>=1.29.101
Requires-Dist: beautifulsoup4>=4.12.2
Requires-Dist: markdown>=3.4.3
Requires-Dist: pytest>=7.2.2
Requires-Dist: pytest-xdist>=3.2.1
Requires-Dist: nltk>=3.8.1
Requires-Dist: textstat>=0.7.3
Requires-Dist: pypandoc>=1.11; sys_platform == "darwin" and platform_machine == "arm64"
Requires-Dist: pypandoc_binary>=1.11; platform_machine == "x86_64"
Requires-Dist: pypandoc_binary>=1.11; platform_system == "Windows"
Requires-Dist: python-magic-bin>=0.4.14; platform_system == "Windows"
Requires-Dist: openpyxl>=3.1.2
Requires-Dist: lm_dataformat>=0.0.20
Requires-Dist: bioc>=2.0
Requires-Dist: sentence_transformers>=3.0.1
Requires-Dist: InstructorEmbedding==1.0.1
Requires-Dist: sentence-transformers>=2.2.2
Requires-Dist: einops>=0.6.1
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: json_repair>=0.21.0
Requires-Dist: text-generation>=0.7.0
Requires-Dist: tiktoken>=0.5.2
Requires-Dist: openai>=1.40.1
Requires-Dist: slowapi>=0.1.9
Requires-Dist: pyexiv2
Requires-Dist: requests>=2.31.0
Requires-Dist: httpx>=0.24.1
Requires-Dist: urllib3>=1.26.16
Requires-Dist: filelock>=3.12.2
Requires-Dist: joblib>=1.3.1
Requires-Dist: tqdm>=4.65.0
Requires-Dist: tabulate>=0.9.0
Requires-Dist: packaging>=23.1
Requires-Dist: jsonschema>=4.23.0
Requires-Dist: spacy==3.7.5
Requires-Dist: torch==2.2.1; sys_platform != "darwin" and platform_machine != "arm64"
Requires-Dist: torch==2.3.1; sys_platform == "darwin" and platform_machine == "arm64"
Requires-Dist: langchain==0.2.6
Requires-Dist: langchain_experimental==0.0.62
Requires-Dist: langchain-community==0.2.6
Requires-Dist: langsmith==0.1.82
Requires-Dist: langchain-core==0.2.23
Requires-Dist: langchain-text-splitters==0.2.2
Requires-Dist: pypdf>=3.17.1
Requires-Dist: pypdfium2>=4.24.0
Requires-Dist: sentence_transformers>=3.0.1
Requires-Dist: InstructorEmbedding==1.0.1
Requires-Dist: sentence-transformers>=2.2.2
Requires-Dist: replicate>=0.26.0
Requires-Dist: anthropic>=0.34.2
Requires-Dist: langchain-anthropic>=0.1.20
Requires-Dist: together>=1.1.5
Requires-Dist: langchain_together==0.1.3
Requires-Dist: langchain-openai>=0.1.8
Requires-Dist: langchain-google-genai>=1.0.8
Requires-Dist: google-generativeai>=0.7.2
Requires-Dist: google-ai-generativelanguage>=0.6.6
Requires-Dist: httpx>=0.25.2
Requires-Dist: httpx-sse>=0.3.1
Requires-Dist: mistralai>=0.4.0
Requires-Dist: groq>=0.5.0
Requires-Dist: langchain-groq>=0.1.5
Requires-Dist: chromadb==0.4.23
Requires-Dist: pydantic-settings>=2.1.0
Requires-Dist: unstructured[local-inference]==0.12.5
Requires-Dist: unstructured[all-docs]==0.12.5
Requires-Dist: docx2txt==0.8
Requires-Dist: python-docx==1.1.0
Requires-Dist: pillow>=10.2.0
Requires-Dist: posthog
Requires-Dist: pdfminer.six==20231228
Requires-Dist: urllib3
Requires-Dist: requests_file
Requires-Dist: tabulate>=0.9.0
Requires-Dist: jq>=1.4.1; platform_machine == "x86_64"
Requires-Dist: pip-licenses>=4.3.0
Requires-Dist: weaviate-client==3.26.2
Requires-Dist: gradio_pdf>=0.0.7
Requires-Dist: gradio_tools>=0.0.9
Requires-Dist: qdrant-client>=1.8.0
Requires-Dist: arxiv>=2.1.3
Requires-Dist: gpt4all==1.0.5
Requires-Dist: llama-cpp-python==0.2.87
Requires-Dist: pymupdf>=1.23.8
Requires-Dist: pymupdf4llm>=0.0.12
Requires-Dist: google-search-results>=2.4.2
Requires-Dist: duckduckgo-search>=4.1.1
Requires-Dist: gradio_tools>=0.0.9
Requires-Dist: wikipedia>=1.4.0
Requires-Dist: wolframalpha>=5.0.0
Requires-Dist: semanticscholar>=0.7.0
Requires-Dist: sympy>=1.12
Requires-Dist: pyautogen==0.2.33
Requires-Dist: flaml==2.2.0
Requires-Dist: pyautogen[redis]
Requires-Dist: pyautogen[retrievechat]
Requires-Dist: pyautogen[lmm]
Requires-Dist: pyautogen[graph]
Requires-Dist: pyautogen[long-context]
Requires-Dist: sympy
Requires-Dist: seaborn
Requires-Dist: scikit-learn
Requires-Dist: statsmodels
Requires-Dist: plotly
Requires-Dist: numpy
Requires-Dist: lightgbm
Requires-Dist: nltk
Requires-Dist: spacy
Requires-Dist: opencv-python
Requires-Dist: opencv-python-headless
Requires-Dist: textblob
Requires-Dist: imageio
Requires-Dist: bokeh
Requires-Dist: altair
Requires-Dist: bs4
Requires-Dist: requests
Requires-Dist: lxml
Requires-Dist: httpx
Requires-Dist: scrapy
Requires-Dist: wolframalpha
Requires-Dist: semanticscholar
Requires-Dist: googlesearch-python
Requires-Dist: google-search-results
Requires-Dist: reportlab
Requires-Dist: yfinance
Requires-Dist: svglib
Requires-Dist: cairosvg
Requires-Dist: pdf2image
Requires-Dist: pydot
Requires-Dist: PyPDF2
Requires-Dist: tzlocal
Requires-Dist: seaborn
Requires-Dist: msrest
Requires-Dist: azure-core
Requires-Dist: azure-common
Requires-Dist: msrestazure
Requires-Dist: microsoft-bing-websearch
Requires-Dist: microsoft-bing-visualsearch
Requires-Dist: microsoft-bing-videosearch
Requires-Dist: microsoft-bing-imagesearch
Requires-Dist: microsoft-bing-newssearch
Requires-Dist: microsoft-bing-customimagesearch
Requires-Dist: microsoft-bing-customwebsearch
Requires-Dist: h2o_engine_manager
Requires-Dist: h2o_authn
Requires-Dist: playwright>=1.37.0
Requires-Dist: selenium>=4.11.2
Requires-Dist: html2text>=2020.1.16
Requires-Dist: bs4>=0.0.1
Requires-Dist: python-doctr@ git+https://github.com/h2oai/doctr.git@aee9b1c369e37af9e18265660935bce2c4447d65
Requires-Dist: weasyprint>=60.1
Requires-Dist: imutils>=0.5.4
Requires-Dist: opencv-python-headless>=4.8.1.78
Requires-Dist: pydub>=0.25.1
Requires-Dist: librosa>=0.10.1
Requires-Dist: ffmpeg>=1.4
Requires-Dist: yt_dlp>=2024.10.22
Requires-Dist: wavio>=0.0.8
Requires-Dist: soundfile==0.12.1
Requires-Dist: torchaudio
Requires-Dist: soundfile>=0.12.1
Requires-Dist: noisereduce
Requires-Dist: emoji
Requires-Dist: ffmpeg-python
Requires-Dist: trainer
Requires-Dist: pysbd
Requires-Dist: coqpit
Requires-Dist: cutlet>=0.3.0
Requires-Dist: langid>=1.1.6
Requires-Dist: g2pkk>=0.1.2
Requires-Dist: jamo>=0.4.1
Requires-Dist: gruut[de,es,fr]>=2.2.3
Requires-Dist: jieba>=0.42.1
Requires-Dist: fiftyone>=0.24.1
Requires-Dist: pytube
Requires-Dist: diffusers>=0.29.0
Requires-Dist: yt-dlp>=2024.8.6
Requires-Dist: pytubefix==8.1.1
Provides-Extra: cpu
Requires-Dist: faiss-cpu>=1.7.4; extra == "cpu"
Requires-Dist: onnxruntime==1.15.0; extra == "cpu"
Provides-Extra: cuda
Requires-Dist: faiss-gpu>=1.7.2; extra == "cuda"
Requires-Dist: onnxruntime-gpu==1.15.0; extra == "cuda"
Requires-Dist: auto-gptq>=0.7.1; extra == "cuda"
Requires-Dist: autoawq; extra == "cuda"
Requires-Dist: autoawq-kernels; extra == "cuda"
Requires-Dist: exllama@ https://github.com/jllllll/exllama/releases/download/0.0.18/exllama-0.0.18+cu121-cp310-cp310-linux_x86_64.whl ; extra == "cuda"
Provides-Extra: training
Requires-Dist: tensorboard>=2.13.0; extra == "training"
Requires-Dist: neptune>=1.2.0; extra == "training"
Provides-Extra: wiki
Requires-Dist: mwxml>=0.3.3; extra == "wiki"
Requires-Dist: mwparserfromhell>=0.6.4; extra == "wiki"
Provides-Extra: local-inference
Requires-Dist: unstructured[local-inference]<0.13,>=0.12.5; extra == "local-inference"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Quantum Documents

Turn ‚òÖ into ‚≠ê (top-right corner) if you like the project!

Query and summarize your documents or just chat with local private GPT LLMs using Quantum Documents, an Apache V2 open-source project.

Check out a long CoT Open-o1 open üçìstrawberryüçì project: https://github.com/pseudotensor/open-strawberry

## Live Demo

[![img-small.png](docs/img-small.png) Gradio Demo](https://gpt.h2o.ai/)

[![img-small.png](docs/img-small.png) OpenWebUI Demo](https://gpt-docs.h2o.ai/)

## Video Demo

https://github.com/h2oai/Quantum Documents/assets/2249614/2f805035-2c85-42fb-807f-fd0bca79abc6

[![img-small.png](docs/img-small.png) YouTube 4K Video](https://www.youtube.com/watch?v=_iktbj4obAI)

## Features

- **Private** offline database of any documents [(PDFs, Excel, Word, Images, Video Frames, YouTube, Audio, Code, Text, MarkDown, etc.)](docs/README_LangChain.md#supported-datatypes)
  - **Persistent** database (Chroma, Weaviate, or in-memory FAISS) using accurate embeddings (instructor-large, all-MiniLM-L6-v2, etc.)
  - **Efficient** use of context using instruct-tuned LLMs (no need for LangChain's few-shot approach)
  - **Parallel** summarization and extraction, reaching an output of 80 tokens per second with the 13B LLaMa2 model
  - **HYDE** (Hypothetical Document Embeddings) for enhanced retrieval based upon LLM responses
  - **Semantic Chunking** for better document splitting (requires GPU)
- **Variety** of models supported (LLaMa2, Mistral, Falcon, Vicuna, WizardLM.  With AutoGPTQ, 4-bit/8-bit, LORA, etc.)
  - **GPU** support from HF and LLaMa.cpp GGML models, and **CPU** support using HF, LLaMa.cpp, and GPT4ALL models
  - **Attention Sinks** for [arbitrarily long](https://github.com/tomaarsen/attention_sinks) generation (LLaMa-2, Mistral, MPT, Pythia, Falcon, etc.)
- **Gradio UI** or CLI with streaming of all models
  - **Upload** and **View** documents through the UI (control multiple collaborative or personal collections)
  - **Vision Models** LLaVa, Claude-3, Gemini-Pro-Vision, GPT-4-Vision
  - **Image Generation** Stable Diffusion (sdxl-turbo, sdxl, SD3), PlaygroundAI (playv2), and Flux
  - **Voice STT** using Whisper with streaming audio conversion
  - **Voice TTS** using MIT-Licensed Microsoft Speech T5 with multiple voices and Streaming audio conversion
  - **Voice TTS** using MPL2-Licensed TTS including Voice Cloning and Streaming audio conversion
  - **AI Assistant Voice Control Mode** for hands-free control of Quantum Documents chat
  - **Bake-off** UI mode against many models at the same time
  - **Easy Download** of model artifacts and control over models like LLaMa.cpp through the UI
  - **Authentication** in the UI by user/password via Native or Google OAuth
  - **State Preservation** in the UI by user/password
- **Open Web UI** with Quantum Documents as backend via OpenAI Proxy
  - See [Start-up Docs](docs/FAQ.md#open-web-ui).
  - Chat completion with streaming
  - Document Q/A using Quantum Documents ingestion with advanced OCR from DocTR
  - Vision models
  - Audio Transcription (STT)
  - Audio Generation (TTS)
  - Image generation
  - Authentication
  - State preservation
- **Linux, Docker, macOS, and Windows** support
- **Inference Servers** [support](docs/README_InferenceServers.md) for oLLaMa, HF TGI server, vLLM, Gradio, ExLLaMa, Replicate, Together.ai, OpenAI, Azure OpenAI, Anthropic, MistralAI, Google, and Groq
- **OpenAI compliant**
  - Server Proxy [API](docs/README_CLIENT.md) (Quantum Documents acts as drop-in-replacement to OpenAI server)
  - Chat and Text Completions (streaming and non-streaming)
  - Audio Transcription (STT)
  - Audio Generation (TTS)
  - Image Generation
  - Embedding
  - Function tool calling w/auto tool selection
  - AutoGen Code Execution Agent
- **JSON Mode**
  - Strict schema control for vLLM via its use of outlines
  - Strict schema control for OpenAI, Anthropic, Google Gemini, MistralAI models
  - JSON mode for some older OpenAI or Gemini models with schema control if model is smart enough (e.g. gemini 1.5 flash)
  - Any model via code block extraction
- **Web-Search** integration with Chat and Document Q/A
- **Agents** for Search, Document Q/A, Python Code, CSV frames
  - High quality Agents via OpenAI proxy server on separate port
  - Code-first agent that generates plots, researches, evaluates images via vision model, etc. (client code openai_server/openai_client.py).
  - No UI for this, just API
- **Evaluate** performance using reward models
- **Quality** maintained with over 1000 unit and integration tests taking over 24 GPU-hours

## Get Started

[![GitHub license](https://img.shields.io/github/license/NVIDIA/nvidia-docker?style=flat-square)](LICENSE)
[![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)](https://github.com/h2oai/Quantum Documents/blob/main/docs/README_LINUX.md)
[![macOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=macos&logoColor=F0F0F0)](https://github.com/h2oai/Quantum Documents/blob/main/docs/README_MACOS.md)
[![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)](https://github.com/h2oai/Quantum Documents/blob/main/docs/README_WINDOWS.md)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)](https://github.com/h2oai/Quantum Documents/blob/main/docs/README_DOCKER.md)

### Install Quantum Documents

Docker is recommended for Linux, Windows, and MAC for full capabilities.  Linux Script also has full capability, while Windows and MAC scripts have less capabilities than using Docker.

* [Docker Build and Run Docs (Linux, Windows, MAC)](docs/README_DOCKER.md)
* [Linux Install and Run Docs](docs/README_LINUX.md)
* [Windows 10/11 Installation Script](docs/README_WINDOWS.md)
* [MAC Install and Run Docs](docs/README_MACOS.md)
* [Quick Start on any Platform](docs/README_quickstart.md)

---

### Collab Demos
- [![](https://colab.research.google.com/assets/colab-badge.svg) Quantum Documents CPU](https://colab.research.google.com/drive/13RiBdAFZ6xqDwDKfW6BG_-tXfXiqPNQe?usp=sharing)
- [![](https://colab.research.google.com/assets/colab-badge.svg) Quantum Documents GPU](https://colab.research.google.com/drive/143-KFHs2iCqXTQLI2pFCDiR69z0dR8iE?usp=sharing)

### Resources
- [FAQs](docs/FAQ.md)
- [README for LangChain](docs/README_LangChain.md)
- [Discord](https://discord.gg/WKhYMWcVbq)
- [Models (LLaMa-2, Falcon 40, etc.) at ü§ó](https://huggingface.co/h2oai/)
- [YouTube: 100% Offline ChatGPT Alternative?](https://www.youtube.com/watch?v=Coj72EzmX20)
- [YouTube: Ultimate Open-Source LLM Showdown (6 Models Tested) - Surprising Results!](https://www.youtube.com/watch?v=FTm5C_vV_EY)
- [YouTube: Blazing Fast Falcon 40b üöÄ Uncensored, Open-Source, Fully Hosted, Chat With Your Docs](https://www.youtube.com/watch?v=H8Dx-iUY49s)
- [Technical Paper: https://arxiv.org/pdf/2306.08161.pdf](https://arxiv.org/pdf/2306.08161.pdf)

### Docs Guide
<!--  cat README.md | ./gh-md-toc  -  But Help is heavily processed -->
* [Get Started](#get-started)
   * [Linux (CPU or CUDA)](docs/README_LINUX.md)
   * [macOS (CPU or M1/M2)](docs/README_MACOS.md)
   * [Windows 10/11 (CPU or CUDA)](docs/README_WINDOWS.md)
   * [GPU (CUDA, AutoGPTQ, exllama) Running Details](docs/README_GPU.md)
   * [CPU Running Details](docs/README_CPU.md)
   * [CLI chat](docs/README_CLI.md)
   * [Gradio UI](docs/README_ui.md)
   * [Client API (Gradio, OpenAI-Compliant)](docs/README_CLIENT.md)
   * [Inference Servers (oLLaMa, HF TGI server, vLLM, Groq, Anthropic, Google, Mistral, Gradio, ExLLaMa, Replicate, OpenAI, Azure OpenAI)](docs/README_InferenceServers.md)
   * [Build Python Wheel](docs/README_WHEEL.md)
   * [Offline Installation](docs/README_offline.md)
   * [Low Memory](docs/FAQ.md#low-memory-mode)
   * [Docker](docs/README_DOCKER.md)
* [LangChain Document Support](docs/README_LangChain.md)
* [Compare to PrivateGPT et al.](docs/README_LangChain.md#what-is-Quantum Documentss-langchain-integration-like)
* [Roadmap](#roadmap)
* [Development](#development)
* [Help](#help)
   * [LangChain file types supported](docs/README_LangChain.md#supported-datatypes)
   * [CLI Database control](docs/README_LangChain.md#database-creation)
   * [FAQ](docs/FAQ.md)
     * [Model Usage Notes](docs/FAQ.md#model-usage-notes)
     * [Adding LLM Models (including using GGUF and Attention Sinks)](docs/FAQ.md#adding-models)
     * [Adding Embedding Models](docs/FAQ.md#add-new-embedding-model)
     * [Adding Prompts](docs/FAQ.md#adding-prompt-templates)
     * [In-Context Learning](docs/FAQ.md#in-context-learning-via-prompt-engineering)
     * [Multiple GPUs](docs/FAQ.md#multiple-gpus)
     * [Low-Memory Usage](docs/FAQ.md#low-memory-mode)
     * [Environment Variables](docs/FAQ.md#what-envs-can-i-pass-to-control-Quantum Documents)
     * [HTTPS access for server and client](docs/FAQ.md#https-access-for-server-and-client)
   * [Useful Links](docs/LINKS.md)
   * [Fine-Tuning](docs/FINETUNE.md)
   * [Triton](docs/TRITON.md)
   * [Commercial viability](docs/FAQ.md#commercial-viability)
* [Acknowledgements](#acknowledgements)
* [Why H2O.ai?](#why-h2oai)
* [Disclaimer](#disclaimer)

### Development

- To create a development environment for training and generation, follow the [installation instructions](docs/INSTALL.md).
- To fine-tune any LLM models on your data, follow the [fine-tuning instructions](docs/FINETUNE.md).
- To run Quantum Documents tests:
    ```bash
    pip install requirements-parser pytest-instafail pytest-random-order playsound==1.3.0
    conda install -c conda-forge gst-python -y
    sudo apt-get install gstreamer-1.0
    pip install pygame
    GPT_H2O_AI=0 CONCURRENCY_COUNT=1 pytest --instafail -s -v tests
    # for openai server test on already-running local server
    pytest -s -v -n 4 openai_server/test_openai_server.py::test_openai_client
    ```
  or tweak/run `tests/test4gpus.sh` to run tests in parallel.

### Acknowledgements

* Some training code was based upon March 24 version of [Alpaca-LoRA](https://github.com/tloen/alpaca-lora/).
* Used high-quality created data by [OpenAssistant](https://open-assistant.io/).
* Used base models by [EleutherAI](https://www.eleuther.ai/).
* Used OIG data created by [LAION](https://laion.ai/blog/oig-dataset/).

### Why H2O.ai?

Our [Makers](https://h2o.ai/company/team/) at [H2O.ai](https://h2o.ai) have built several world-class Machine Learning, Deep Learning and AI platforms:
- #1 open-source machine learning platform for the enterprise [H2O-3](https://github.com/h2oai/h2o-3)
- The world's best AutoML (Automatic Machine Learning) with [H2O Driverless AI](https://h2o.ai/platform/ai-cloud/make/h2o-driverless-ai/)
- No-Code Deep Learning with [H2O Hydrogen Torch](https://h2o.ai/platform/ai-cloud/make/hydrogen-torch/)
- Document Processing with Deep Learning in [Document AI](https://h2o.ai/platform/ai-cloud/make/document-ai/)

We also built platforms for deployment and monitoring, and for data wrangling and governance:
- [H2O MLOps](https://h2o.ai/platform/ai-cloud/operate/h2o-mlops/) to deploy and monitor models at scale
- [H2O Feature Store](https://h2o.ai/platform/ai-cloud/make/feature-store/) in collaboration with AT&T
- Open-source Low-Code AI App Development Frameworks [Wave](https://wave.h2o.ai/) and [Nitro](https://nitro.h2o.ai/)
- Open-source Python [datatable](https://github.com/h2oai/datatable/) (the engine for H2O Driverless AI feature engineering)

Many of our customers are creating models and deploying them enterprise-wide and at scale in the [H2O AI Cloud](https://h2o.ai/platform/ai-cloud/):
- Multi-Cloud or on Premises
- [Managed Cloud (SaaS)](https://h2o.ai/platform/ai-cloud/managed)
- [Hybrid Cloud](https://h2o.ai/platform/ai-cloud/hybrid)
- [AI Appstore](https://docs.h2o.ai/h2o-ai-cloud/)

We are proud to have over 25 (of the world's 280) [Kaggle Grandmasters](https://h2o.ai/company/team/kaggle-grandmasters/) call H2O home, including three Kaggle Grandmasters who have made it to world #1.

### Disclaimer

Please read this disclaimer carefully before using the large language model provided in this repository. Your use of the model signifies your agreement to the following terms and conditions.

- Biases and Offensiveness: The large language model is trained on a diverse range of internet text data, which may contain biased, racist, offensive, or otherwise inappropriate content. By using this model, you acknowledge and accept that the generated content may sometimes exhibit biases or produce content that is offensive or inappropriate. The developers of this repository do not endorse, support, or promote any such content or viewpoints.
- Limitations: The large language model is an AI-based tool and not a human. It may produce incorrect, nonsensical, or irrelevant responses. It is the user's responsibility to critically evaluate the generated content and use it at their discretion.
- Use at Your Own Risk: Users of this large language model must assume full responsibility for any consequences that may arise from their use of the tool. The developers and contributors of this repository shall not be held liable for any damages, losses, or harm resulting from the use or misuse of the provided model.
- Ethical Considerations: Users are encouraged to use the large language model responsibly and ethically. By using this model, you agree not to use it for purposes that promote hate speech, discrimination, harassment, or any form of illegal or harmful activities.
- Reporting Issues: If you encounter any biased, offensive, or otherwise inappropriate content generated by the large language model, please report it to the repository maintainers through the provided channels. Your feedback will help improve the model and mitigate potential issues.
- Changes to this Disclaimer: The developers of this repository reserve the right to modify or update this disclaimer at any time without prior notice. It is the user's responsibility to periodically review the disclaimer to stay informed about any changes.

By using the large language model provided in this repository, you agree to accept and comply with the terms and conditions outlined in this disclaimer. If you do not agree with any part of this disclaimer, you should refrain from using the model and any content generated by it.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=h2oai/Quantum Documents&type=Timeline)](https://star-history.com/#h2oai/Quantum Documents&Timeline)
